---
layout: post
title: "The many faces of LLVM PGO and FDO"
date: 2023-07-09
comments: true
---
## Intro

This short note is about PGO, profile-guided optimizations, and FDO, feedback-directed optimizations, 
as implemented in LLVM codebase today (Jul'23). I couldn't find a comprehensive overview of the 
lesser-known variants so I will try to cover them in this note.

## PGO vs FDO
What's up with these two terms? Is there a material difference between the two? To me, there's no.
But these terms are used to distinguish between different implementations which we'll cover later.

## Instrumentation vs sampling profile

There are several ways to collect the profile:

1. **Instrumentation**: modify the program itself so that the profile is recorded during its execution.
Note that instrumentation code can be added either _statically_ by compiler or external tools, Clang PGO is a prime example of which,
or _dynamically_ during program's execution, e.g. Intel's Pin can be used to collect BB profile.
The difference between the two boils down to being able to cover generated code and code from shared libraries.
  Dynamic instrumentation has the benefit of avoiding recompiling the binary while incurring a larger
  runtime overhead.

2. **Sampling**: collect execution profile from unmodified program by leveraging profiling capabilities of
the execution environment (OS or HW or both). The primary mechanism is Linux perf which interrupts 
the program at regular intervals and records the current IP and/or call stack. Modern CPUs enhance sampling
in two important ways:
  - provide programmable events used to interrupt the program (e.g. instructions, cycles, branches, calls) – improves the profile quality,
  - have out-of-band profiling extensions (Intel LBR) that accumulate taken branches in a circular buffer
which greatly enhances both the quantity of profile information (multiple taken branches per sample)
and its quality by providing limited tracing information (branches form a trace).

3. **Tracing**: the control flow is recorded from the program execution, and the profile is aggregated
from the trace. Tracing is the most flexible and expensive option, but its overhead can be reduced with
HW support (e.g. Intel PT). Although I mention it here, it's seldom used in production environments
due to its prohibitive runtime cost.

Hybrid approaches are also possible, specifically those that supplant sampling information with better
code anchors via instrumentation (see CSSPGO below).

## PGO
### Clang Front-end PGO
Instrumentation is inserted at the source level.

Clang flags: `-fprofile-instr-generate/-fprofile-instr-use`.

LLVM CMake options: `LLVM_BUILD_INSTRUMENTED`.

### IR PGO
Instrumentation is inserted at IR level.

Flags: `-fprofile-generate/-fprofile-use`.

LLVM CMake options: `LLVM_BUILD_INSTRUMENTED=IR`, `LLVM_ENABLE_IR_PGO`.

### CSIR PGO
[Clang User Guide](https://clang.llvm.org/docs/UsersManual.html#cmdoption-fcs-profile-generate):
> The difference is that the instrumentation is performed after inlining so that the
> resulted profile has a better context sensitive information.

Flags: `-fcs-profile-generate/-fprofile-use`.

LLVM CMake options: `LLVM_BUILD_INSTRUMENTED=CSIR`.

Example of how to use IR PGO and CSIR PGO together: [link](https://github.com/llvm/llvm-project/issues/56274#issuecomment-1406427363).

### Context-Sensitive Sample PGO (CSSPGO)

[RFC introducing CSSPGO](https://groups.google.com/g/llvm-dev/c/-Ao1uXCi8QM/m/Be9794ZeBAAJ):
> We propose a full context-sensitive sample profiling infrastructure that utilizes
> both LBR and call stack samples at the same time to synthesize a profile with a full
> context sensitivity. The key advantage is that rather than relying on previous
> inlining or a separate profile, the profile collected with the new approach will have
> full calling contexts recovered from both inlined and not inlined call sites.
> To achieve an accurate post-inline profile, a separate profile is no longer needed.
> Instead, the post-inline profile can be directly derived from adjusting the input
> profile based on all inline decisions. The richer context-sensitive profile also
> enables better inline decisions.

How to generate profile for CSSPGO: [link](https://groups.google.com/g/llvm-dev/c/U6zI4M1l1SI).

How to use CSSPGO: [link](https://groups.google.com/g/llvm-dev/c/-Ao1uXCi8QM).

## FDO
### AutoFDO/SampleFDO
FDO in LLVM context is typically a shorthand for AutoFDO – sample profile first developed by Google for GCC. 
[google/autofdo](https://github.com/google/autofdo)

Usage instructions: [Using sampling profilers](https://clang.llvm.org/docs/UsersManual.html#using-sampling-profilers).

### Control Flow-Sensitive Sample AutoFDO (FS-AFDO)
[Control Flow Sensitive AutoFDO (FS-AFDO)](https://lists.llvm.org/pipermail/llvm-dev/2020-November/146694.html)

Sample profile is attached at MachineIR level. (see `MIRSampleProfile.h`)

Usage instructions can be found in Clang's Users Manual.

## PLO: Post-link profile-guided optimizations
Post-link optimizers are by nature "context-sensitive" since they work on the final binary, after all inlining and transformations.
Therefore they target the same performance opportunity as CSIR PGO/CSSPGO. But:
- CSSPGO uses a single profile and its accuracy is lower than the profile used for post-link optimizations.
- CSIR PGO uses the second profile and is supposed to completely subsume post-link optimizations at the cost of second
  recompilation, but surprisingly it still leaves some opportunity to BOLT: [example](https://github.com/llvm/llvm-project/issues/56274#issuecomment-1407117774).

Post-link optimizers can be stacked on top of PGO and provide extra performance benefits, or be used as a faster alternative to CSIR PGO.

### BOLT
BOLT is a post-link binary optimization and layout tool: [BOLT](https://github.com/llvm/llvm-project/tree/main/bolt).

[CGO'19 paper](https://research.facebook.com/publications/bolt-a-practical-binary-optimizer-for-data-centers-and-beyond/).

BOLT can work with both sample and instrumentation profile. BOLT's scalability has been improved over the years – see [Lightning BOLT paper](https://dl.acm.org/doi/10.1145/3446804.3446843).

Using BOLT: [GitHub repo](https://github.com/llvm/llvm-project/tree/main/bolt).

Using BOLT for Clang using CMake: [Advanced Builds](https://llvm.org/docs/AdvancedBuilds.html#bolt).

### Propeller
[Propeller: A frame work for Post Link Optimizations](https://lists.llvm.org/pipermail/llvm-dev/2019-September/135393.html)

Propeller is a link-time layout optimizer designed to address scalability issues of BOLT.
It performs profile-guided code reordering at link-time and therefore relies on the compiler to perform function splitting 
(since linker can only see sections).

Propeller is fully integrated into Clang/LLVM.
